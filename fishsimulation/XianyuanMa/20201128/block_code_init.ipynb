{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import matplotlib.pylab as plt\n",
    "import sys\n",
    "sys.path.append(\"C:/Users/lenovo/Desktop/spliking_nn_for_brain_simulation-master\")\n",
    "import unittest.mock as mock\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "from multiprocessing.pool import Pool as pool\n",
    "from multiprocessing.pool import ThreadPool as Thpool\n",
    "import re\n",
    "from numba import jit #加速器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_for_single_sparse_block(block_idx, k, extern_input_rate, extern_input_k_sizes, degree=int(1e3), init_min=0, init_max=1, s = 0, e = -1):\n",
    "    # extern_input_rate only works for E neurons.\n",
    "\n",
    "    # this function is pertty slow.\n",
    "\n",
    "    # we assume that the permution\n",
    "\n",
    "    if e == -1:\n",
    "        e = k\n",
    "    assert 0 <= s < e <= k\n",
    "\n",
    "    print(\"length:\", e - s, \"degree:\", degree)\n",
    "    print(\"generating weight\")\n",
    "    connect_weight = np.random.rand(e - s, degree, 2).astype(np.float32) * (init_max - init_min) + init_min\n",
    "    print(\"generating idx\")\n",
    "\n",
    "    E_neuron_thresh = extern_input_k_sizes[block_idx]\n",
    "\n",
    "    # connect_weight[is_E_neuron == 0] *= 4\n",
    "\n",
    "    output_neuron_idx = np.broadcast_to(np.arange(s, e, dtype=np.uint32)[:, None], (e-s, degree))\n",
    "\n",
    "    _extern_input_k_sizes = np.array(extern_input_k_sizes, dtype=np.int64)\n",
    "    extern_input_rate = np.add.accumulate(extern_input_rate)[:-1]\n",
    "\n",
    "    @jit(nogil=True, nopython=True)\n",
    "    def _run(i):\n",
    "        input_block_idx = np.zeros(degree, dtype=np.int16)#初始化\n",
    "        input_channel_offset = np.zeros(degree, dtype=np.uint8)#初始化\n",
    "        while True:\n",
    "            k_idx = get_k_idx(k, degree, i)#不能与自己连接\n",
    "            k_idx_is_E = (k_idx < E_neuron_thresh)##与E_neuron产生随机的连接关系？\n",
    "            k_idx_is_I = (k_idx >= E_neuron_thresh)##与I_neuron产生随机的连接关系？\n",
    "            if k_idx_is_I.shape[0] > 0:\n",
    "                break\n",
    "        # connect_weight[i, k_idx_is_I] *= connect_weight[i, k_idx_is_E].sum() / connect_weight[i, k_idx_is_I].sum()\n",
    "\n",
    "        input_block_idx[k_idx_is_I] = block_idx#设置I_neuron\n",
    "\n",
    "        r = np.random.rand(np.count_nonzero(k_idx_is_E))\n",
    "        E_in_comming = np.searchsorted(extern_input_rate, r, 'right').astype(np.int16)\n",
    "\n",
    "        input_block_idx[k_idx_is_E] = E_in_comming#设置E_neuron\n",
    "\n",
    "        input_neuron_idx = k_idx.astype(np.uint32)\n",
    "        for _idx, max_idx in enumerate(_extern_input_k_sizes):\n",
    "            if _idx != block_idx:\n",
    "                extern_incomming_idx = (input_block_idx == _idx).nonzero()[0]\n",
    "                extern_outcomming_idx = get_k_idx(max_idx, extern_incomming_idx.shape[0], -1)\n",
    "                input_neuron_idx[extern_incomming_idx] = extern_outcomming_idx\n",
    "\n",
    "        input_channel_offset[k_idx_is_E] = 0 #设置offset\n",
    "        input_channel_offset[k_idx_is_I] = 2 #设置offset\n",
    "\n",
    "        input_block_idx -= block_idx\n",
    "        return input_block_idx, input_neuron_idx, input_channel_offset\n",
    "\n",
    "    with Thpool() as p:#多线程\n",
    "        input_block_idx, input_neuron_idx, input_channel_offset = tuple(zip(*p.map(_run, range(s, e))))\n",
    "    input_block_idx = np.concatenate(input_block_idx)\n",
    "    input_neuron_idx = np.concatenate(input_neuron_idx)\n",
    "    input_channel_offset = np.concatenate(input_channel_offset)\n",
    "    output_neuron_idx = output_neuron_idx.reshape([-1])\n",
    "    connect_weight = connect_weight.reshape([-1, 2])\n",
    "\n",
    "    print(\"done\", e - s)\n",
    "    return output_neuron_idx, input_block_idx, input_neuron_idx, input_channel_offset, connect_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/lenovo/Desktop/spliking_nn_for_brain_simulation-master/single_small_test/single\\block_0.npz\n",
      "torch.Size([1000, 22]) torch.Size([4, 1000, 1000])\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "dense=True\n",
    "bases =None\n",
    "block_name = re.compile('block_[0-9]*.npz')\n",
    "path = \"C:/Users/lenovo/Desktop/spliking_nn_for_brain_simulation-master/single_small_test/single\"\n",
    "block_length = len([name for name in os.listdir(path) if block_name.fullmatch(name)])#返回指定目录中npz文件的数量\n",
    "#os.listdir() 方法用于返回指定的文件夹包含的文件或文件夹的名字的列表。这个列表以字母顺序。 它不包括 '.' 和'..' 即使它在文件夹中。\n",
    "if bases is None:\n",
    "    bases = [0]\n",
    "    for i in range(block_length):\n",
    "        pkl_path = os.path.join(path, \"block_{}.npz\".format(i))\n",
    "        file = np.load(pkl_path)\n",
    "        bases.append(bases[-1] + file[\"property\"].shape[0])\n",
    "\n",
    "    bases = np.array(bases, dtype=np.int64)\n",
    "\n",
    "if dense:#如果是一般的矩阵\n",
    "    weights = []\n",
    "    indices = []\n",
    "    sizes = []\n",
    "    properties = []\n",
    "    for i in range(block_length):#开始读取每个block中的数据数据\n",
    "        pkl_path = os.path.join(path, \"block_{}.npz\".format(i))\n",
    "        print(pkl_path)\n",
    "        file = np.load(pkl_path)\n",
    "        properties.append(file[\"property\"])\n",
    "        output_neuron_idx, input_block_idx, input_neuron_idx, input_channel_offset, weight = \\\n",
    "            tuple(file[name] for name in [\"output_neuron_idx\", \"input_block_idx\", \"input_neuron_idx\", \"input_channel_offset\", \"weight\"])\n",
    "        idx = np.stack([input_channel_offset.astype(np.uint32),\n",
    "                        output_neuron_idx.astype(np.uint32),\n",
    "                        (bases[(input_block_idx + i)] + input_neuron_idx).astype(np.uint32)])\n",
    "        weight = weight.reshape([-1])\n",
    "        idx = np.stack([idx, idx], axis=-1)\n",
    "        idx[0, :, 1] = idx[0, :, 0] + 1\n",
    "        idx = idx.reshape([3, -1])\n",
    "        size = [4, np.max(idx[1])+1, np.max(idx[2])+1]\n",
    "\n",
    "        indices.append(idx)\n",
    "        weights.append(weight)\n",
    "        sizes.append(size)\n",
    "    size = tuple(np.max(np.array(sizes), axis=0)[1:].tolist())\n",
    "    property = torch.cat([torch.from_numpy(property) for property in properties])\n",
    "    weight = torch.cat([torch.sparse.FloatTensor(\n",
    "                torch.from_numpy(indices[i].astype(np.int64)),\n",
    "                torch.from_numpy(weights[i]),\n",
    "                torch.Size([4, bases[i+1] - bases[i], size[1]])) for i in range(block_length)], dim=2)\n",
    "    assert property.shape[0] == weight.shape[1]\n",
    "    assert weight.shape[2] == weight.shape[1]\n",
    "    print(property.shape, weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###random innitialize###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init(_block_connect_prob,\n",
    "          _block_node_init_kwards,\n",
    "          _extern_input_k_sizes,\n",
    "          _degree,\n",
    "          _init_min,\n",
    "          _init_max,\n",
    "          _dtype,\n",
    "          _perfix):\n",
    "    global block_connect_prob\n",
    "    global block_node_init_kwards\n",
    "    global extern_input_k_sizes\n",
    "    global degree\n",
    "    global init_min\n",
    "    global init_max\n",
    "    global dtype\n",
    "    global perfix\n",
    "\n",
    "    block_connect_prob = _block_connect_prob\n",
    "    block_node_init_kwards = _block_node_init_kwards\n",
    "    extern_input_k_sizes = _extern_input_k_sizes\n",
    "    degree = _degree\n",
    "    init_min = _init_min\n",
    "    init_max = _init_max\n",
    "    dtype = _dtype\n",
    "    perfix = _perfix\n",
    "\n",
    "    np.random.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = 'single'###有关dtype的设置\n",
    "def connect_for_multi_sparse_block(block_connect_prob, block_node_init_kwards=None,\\\n",
    "                                   E_number=None, I_number=None, degree=int(1e3), \\\n",
    "                                   init_min=0, init_max=1, perfix=None, dtype=\"single\"):\n",
    "    assert isinstance(block_connect_prob, torch.Tensor) and \\\n",
    "           len(block_connect_prob.shape) == 2 and \\\n",
    "           block_connect_prob.shape[0] == block_connect_prob.shape[1]\n",
    "    # block_connect_prob should be a [N, N] tensor\n",
    "    N = block_connect_prob.shape[0]\n",
    "    block_connect_prob = block_connect_prob.numpy()\n",
    "\n",
    "    #参数设置整理\n",
    "    block_node_init_kwards = {} if block_node_init_kwards is None else block_node_init_kwards\n",
    "    if E_number is not None:\n",
    "        block_node_init_kwards[\"E_number\"] = E_number\n",
    "    if I_number is not None:\n",
    "        block_node_init_kwards[\"I_number\"] = I_number\n",
    "\n",
    "    if isinstance(block_node_init_kwards, dict):\n",
    "        extern_input_k_sizes = [block_node_init_kwards[\"E_number\"]] * N\n",
    "    elif isinstance(block_node_init_kwards, list):\n",
    "        extern_input_k_sizes = [b[\"E_number\"] for b in block_node_init_kwards]\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    print('total {} blocks'.format(N))\n",
    "    if perfix is None:\n",
    "        def _out():\n",
    "            if isinstance(block_node_init_kwards, dict):\n",
    "                number = [block_node_init_kwards['E_number'] + block_node_init_kwards['I_number']] * N\n",
    "            elif isinstance(block_node_init_kwards, list):\n",
    "                number = [b['E_number'] + b['I_number'] for b in block_node_init_kwards]\n",
    "            else:\n",
    "                raise ValueError\n",
    "\n",
    "            bases = np.add.accumulate(np.array(number, dtype=np.int64))\n",
    "            bases = np.concatenate([np.array([0], dtype=np.int64), bases])\n",
    "\n",
    "            def prop(i, s, e):\n",
    "                block_node_init_kward = block_node_init_kwards[i] if isinstance(block_node_init_kwards, list) else block_node_init_kwards#剥壳\n",
    "                return generate_block_node_property(sub_block_idx=i, s=s, e=e, **block_node_init_kward)\n",
    "\n",
    "            def conn(i, s, e):\n",
    "                prob = block_connect_prob[i, :]\n",
    "                assert np.abs(1 - prob.sum()) < 1e-4\n",
    "                step = int(1e6)\n",
    "                for _s in range(s, e, step):\n",
    "                    _e = min(_s+step, e)\n",
    "                    output_neuron_idx, input_block_idx, input_neuron_idx, input_neuron_offset, connect_weight =\\\n",
    "                        connect_for_single_sparse_block(i, bases[i+1] - bases[i],\n",
    "                                                          prob,\n",
    "                                                          s=_s,\n",
    "                                                          e=_e,\n",
    "                                                          extern_input_k_sizes=extern_input_k_sizes,\n",
    "                                                          degree=degree,\n",
    "                                                          init_min=init_min,\n",
    "                                                          init_max=init_max)\n",
    "\n",
    "                    output_neuron_idx = output_neuron_idx.astype(np.int64)\n",
    "                    input_neuron_idx = input_neuron_idx.astype(np.int64)\n",
    "\n",
    "                    output_neuron_idx += bases[i].astype(output_neuron_idx.dtype)\n",
    "                    input_neuron_idx += bases[i + input_block_idx].astype(input_neuron_idx.dtype)\n",
    "                    yield output_neuron_idx, input_neuron_idx, input_neuron_offset, connect_weight\n",
    "            return prop, conn, bases\n",
    "        return _out\n",
    "    else:\n",
    "        if not os.path.exists(perfix):\n",
    "            os.makedirs(perfix)\n",
    "        with pool(8, initializer=_init, initargs=(block_connect_prob,\n",
    "                                               block_node_init_kwards,\n",
    "                                               extern_input_k_sizes,\n",
    "                                               degree,\n",
    "                                               init_min,\n",
    "                                               init_max,\n",
    "                                               dtype,\n",
    "                                               perfix)) as p:\n",
    "            p.map(_process_dti, range(0, N, 1), chunksize=1)\n",
    "\n",
    "        print('total done!')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_dti(i):\n",
    "    global block_connect_prob\n",
    "    global block_node_init_kwards\n",
    "    global extern_input_k_sizes\n",
    "    global degree\n",
    "    global init_min\n",
    "    global init_max\n",
    "    global dtype\n",
    "    global perfix\n",
    "    print(\"dtype: {}\".format(dtype))\n",
    "    def check_if_exist():\n",
    "        for d in dtype:\n",
    "            print(\"d: {}\".format(d))\n",
    "            new_perfix = perfix if len(dtype) == 0 else os.path.join(perfix, d)\n",
    "            os.makedirs(new_perfix, exist_ok=True)\n",
    "            if not os.path.exists(os.path.join(new_perfix, \"block_{}.npz\".format(i))):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    if check_if_exist():\n",
    "        print(\"skip\", i)\n",
    "        return\n",
    "    print(\"processing\", i)\n",
    "    prob = block_connect_prob[i, :]\n",
    "    assert np.abs(1 - prob.sum()) < 1e-4#概率加起来基本上等于1\n",
    "    if isinstance(block_node_init_kwards, list):#剥皮\n",
    "        block_node_init_kward = block_node_init_kwards[i]\n",
    "    else:\n",
    "        block_node_init_kward = block_node_init_kwards\n",
    "    assert isinstance(block_node_init_kward, dict)\n",
    "    property = generate_block_node_property(sub_block_idx=i, **block_node_init_kward)\n",
    "    output_neuron_idx, input_block_idx, input_neuron_idx, input_channel_offset, weight \\\n",
    "        = connect_for_single_sparse_block(i, block_node_init_kward['E_number'] + block_node_init_kward['I_number'],\n",
    "                                             prob,\n",
    "                                             extern_input_k_sizes=extern_input_k_sizes,\n",
    "                                             degree=degree,\n",
    "                                             init_min=init_min,\n",
    "                                             init_max=init_max)\n",
    "\n",
    "    if isinstance(dtype, str):\n",
    "        dtype = [dtype]\n",
    "\n",
    "    for d in dtype:\n",
    "        new_perfix = perfix if len(dtype) == 0 else os.path.join(perfix, d)\n",
    "        os.makedirs(new_perfix, exist_ok=True)\n",
    "\n",
    "        if d == \"single\":\n",
    "            _weight = weight\n",
    "        elif d == 'half':\n",
    "            _weight = weight.astype(np.float16)\n",
    "        else:\n",
    "            raise ValueError\n",
    "        np.savez(os.path.join(new_perfix, \"block_{}\".format(i)),\n",
    "                 property=np.ascontiguousarray(property),\n",
    "                 output_neuron_idx=np.ascontiguousarray(output_neuron_idx),\n",
    "                 input_block_idx=np.ascontiguousarray(input_block_idx),\n",
    "                 input_neuron_idx=np.ascontiguousarray(input_neuron_idx),\n",
    "                 input_channel_offset=np.ascontiguousarray(input_channel_offset),\n",
    "                 weight=np.ascontiguousarray(_weight))\n",
    "\n",
    "    print(\"done! \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_for_single_sparse_block(block_idx: object, k: object, extern_input_rate: object, extern_input_k_sizes: object, degree: object = int(1e3),\n",
    "                                    init_min: object = 0,\n",
    "                                    init_max: object = 1,\n",
    "                                    s: object = 0,\n",
    "                                    e: object = -1) -> object:\n",
    "    # extern_input_rate only works for E neurons.\n",
    "\n",
    "    # this function is pertty slow.\n",
    "\n",
    "    # we assume that the permution\n",
    "\n",
    "    if e == -1:\n",
    "        e = k\n",
    "    assert 0 <= s < e <= k\n",
    "\n",
    "    print(\"length:\", e - s, \"degree:\", degree)\n",
    "    print(\"generating weight\")\n",
    "    connect_weight = np.random.rand(e - s, degree, 2).astype(np.float32) * (init_max - init_min) + init_min\n",
    "    print(\"generating idx\")\n",
    "\n",
    "    E_neuron_thresh = extern_input_k_sizes[block_idx]\n",
    "\n",
    "    # connect_weight[is_E_neuron == 0] *= 4\n",
    "\n",
    "    output_neuron_idx = np.broadcast_to(np.arange(s, e, dtype=np.uint32)[:, None], (e-s, degree))\n",
    "\n",
    "    _extern_input_k_sizes = np.array(extern_input_k_sizes, dtype=np.int64)\n",
    "    extern_input_rate = np.add.accumulate(extern_input_rate)[:-1]\n",
    "\n",
    "    @jit(nogil=True, nopython=True)\n",
    "    def _run(i):\n",
    "        input_block_idx = np.zeros(degree, dtype=np.int16)#初始化在本脑区内部输入的神经元index集\n",
    "        input_channel_offset = np.zeros(degree, dtype=np.uint8)#初始化在本脑区内部输入的神经元的channel_offset\n",
    "        while True:\n",
    "            k_idx = get_k_idx(k, degree, i)#随机选择degree个非己的神经元作为出度，k为最大的神经元index，degree为出度\n",
    "            k_idx_is_E = (k_idx < E_neuron_thresh)##与E_neuron产生随机的连接关系？\n",
    "            k_idx_is_I = (k_idx >= E_neuron_thresh)##与I_neuron产生随机的连接关系？\n",
    "            if k_idx_is_I.shape[0] > 0:\n",
    "                break\n",
    "        # connect_weight[i, k_idx_is_I] *= connect_weight[i, k_idx_is_E].sum() / connect_weight[i, k_idx_is_I].sum()\n",
    "\n",
    "        input_block_idx[k_idx_is_I] = block_idx#设置I_neuron\n",
    "        \n",
    "        #与其他脑区的进入进出\n",
    "        r = np.random.rand(np.count_nonzero(k_idx_is_E))\n",
    "        E_in_comming = np.searchsorted(extern_input_rate, r, 'right').astype(np.int16)\n",
    "\n",
    "        input_block_idx[k_idx_is_E] = E_in_comming#设置E_neuron\n",
    "\n",
    "        input_neuron_idx = k_idx.astype(np.uint32)\n",
    "        for _idx, max_idx in enumerate(_extern_input_k_sizes):#与其他脑区的进入进出\n",
    "            if _idx != block_idx:\n",
    "                extern_incomming_idx = (input_block_idx == _idx).nonzero()[0]\n",
    "                extern_outcomming_idx = get_k_idx(max_idx, extern_incomming_idx.shape[0], -1)\n",
    "                input_neuron_idx[extern_incomming_idx] = extern_outcomming_idx\n",
    "\n",
    "        input_channel_offset[k_idx_is_E] = 0 #设置offset\n",
    "        input_channel_offset[k_idx_is_I] = 2 #设置offset\n",
    "\n",
    "        input_block_idx -= block_idx\n",
    "        return input_block_idx, input_neuron_idx, input_channel_offset\n",
    "\n",
    "    with Thpool() as p:#多线程\n",
    "        input_block_idx, input_neuron_idx, input_channel_offset = tuple(zip(*p.map(_run, range(s, e))))\n",
    "    input_block_idx = np.concatenate(input_block_idx)\n",
    "    input_neuron_idx = np.concatenate(input_neuron_idx)\n",
    "    input_channel_offset = np.concatenate(input_channel_offset)\n",
    "    output_neuron_idx = output_neuron_idx.reshape([-1])\n",
    "    connect_weight = connect_weight.reshape([-1, 2])\n",
    "\n",
    "    print(\"done\", e - s)\n",
    "    return output_neuron_idx, input_block_idx, input_neuron_idx, input_channel_offset, connect_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_block_node_property(E_number=int(8e5),\n",
    "                            I_number=int(2e5),\n",
    "                            I_extern_Input = 0,\n",
    "                            sub_block_idx=0,\n",
    "                            C = 1,\n",
    "                            T_ref = 5,\n",
    "                            g_Li = 0.001,\n",
    "                            V_L = -75,\n",
    "                            V_th = -50,\n",
    "                            V_reset = -65,\n",
    "                            g_ui = (5/275, 5/4000, 3/30, 3/730),\n",
    "                            V_ui = (0, 0, -70, -100),\n",
    "                            tao_ui = (2, 40, 10, 50),\n",
    "                            s = 0, e = -1):\n",
    "\n",
    "    # each node contain such property:\n",
    "    #          E/I, blocked_in_stat, I_extern_Input, sub_block_idx, C, T_ref, g_Li, V_L, V_th, V_reset, g_ui, V_ui, tao_ui\n",
    "    #   size:  1,   1,               1,                1,           1, 1,     1,    1,   1,    1,       4     4,    4\n",
    "    #   dtype: b,   b,               f,                i,           f, f,     f,    f,   f,    f,       f,    f,    f\n",
    "    # b means bool(although storage as float), f means float.\n",
    "\n",
    "    # this function support broadcast, e.g, C can be a scalar for a total block or a [E_number, I_number] tensor for total nodes.\n",
    "    if e == -1:\n",
    "        e = E_number + I_number\n",
    "    assert 0 <= s < e <= E_number + I_number\n",
    "\n",
    "    property = np.zeros([e - s, 22], dtype=np.float32)\n",
    "    E_thresh = E_number - s if E_number > s else 0\n",
    "    property[:E_thresh, 0] = 1\n",
    "    property[E_thresh:, 0] = 0\n",
    "\n",
    "    property[:, 1] = 0\n",
    "\n",
    "    property[:, 2] = I_extern_Input\n",
    "\n",
    "    property[:, 3] = sub_block_idx\n",
    "    property[:, 4] = C\n",
    "    property[:, 5] = T_ref\n",
    "    property[:, 6] = g_Li\n",
    "    property[:, 7] = V_L\n",
    "    property[:, 8] = V_th\n",
    "    property[:, 9] = V_reset\n",
    "\n",
    "    g_ui = g_ui if isinstance(g_ui, np.ndarray) else np.array(g_ui)\n",
    "    property[:, 10:14] = g_ui\n",
    "\n",
    "    V_ui = V_ui if isinstance(V_ui, np.ndarray) else np.array(V_ui)\n",
    "    property[:, 14:18] = V_ui\n",
    "\n",
    "    tao_ui = tao_ui if isinstance(tao_ui, np.ndarray) else np.array(tao_ui)\n",
    "\n",
    "    property[:, 18:22] = tao_ui\n",
    "\n",
    "    return property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nogil=True, nopython=True)\n",
    "def get_k_idx(max_k, num, except_idx):\n",
    "    if except_idx < 0:\n",
    "        assert num <= max_k\n",
    "        if num == max_k:\n",
    "            return np.arange(0, max_k)\n",
    "    elif except_idx is not None:\n",
    "        assert num < max_k\n",
    "        if num == max_k - 1:\n",
    "            return np.concatenate((np.arange(0, except_idx), np.arange(except_idx+1, num)))#输出除了except_idx之外的其他连续数列，从0到num\n",
    "\n",
    "    while True:\n",
    "        k_idx = np.unique(np.random.randint(0, max_k, num*2))#随机生成一个2*num规模的随机整数列，去掉重复值，取值为0-max_k\n",
    "        k_idx = k_idx[np.random.permutation(k_idx.shape[0])]#对上述产生的序列进行随机打乱\n",
    "        if except_idx is not None:\n",
    "            k_idx = k_idx[k_idx != except_idx] #删掉except_idx\n",
    "        k_idx = k_idx[:num]#截取num个元素\n",
    "        if k_idx.shape[0] == num:\n",
    "            break\n",
    "    return k_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-c24d241a96bd>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-c24d241a96bd>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    (block_connect_prob, block_node_init_kwards=None,E_number=None, I_number=None, degree=int(1e3),init_min=0, init_max=1, perfix=None, dtype=\"single\")\u001b[0m\n\u001b[1;37m                                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "(block_connect_prob, block_node_init_kwards=None,E_number=None, I_number=None, degree=int(1e3),init_min=0, init_max=1, perfix=None, dtype=\"single\")\n",
    "connect_for_multi_sparse_block(block_connect_prob=prob, \n",
    "                               block_node_init_kwards={'g_Li': 0.003,\n",
    "                                      'g_ui': (0.022178268060088158,\n",
    "                                               0.0013867146335542202,\n",
    "                                               0.09227322041988373,\n",
    "                                               0.004128940403461456),\n",
    "                                      \"V_reset\": -65,\n",
    "                                      \"V_th\": -50},\n",
    "                               E_number=int(8e2), \n",
    "                               I_number=int(2e2), \n",
    "                               degree=int(20), \n",
    "                               init_min=0, \n",
    "                               init_max=1, \n",
    "                               perfix=\"./single_small/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_connect_prob=torch.tensor([[1.]])\n",
    "block_node_init_kwards={'g_Li': 0.003,\n",
    "'g_ui': (0.022178268060088158,\n",
    "0.0013867146335542202,\n",
    "0.09227322041988373,\n",
    "0.004128940403461456),\n",
    "\"V_reset\": -65,\n",
    "\"V_th\": -50};\n",
    "E_number=int(8e2)\n",
    "I_number=int(2e2)\n",
    "degree=int(20)\n",
    "init_min=0\n",
    "init_max=1\n",
    "perfix=\"./my_single_small/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(block_connect_prob, torch.Tensor) and \\\n",
    "       len(block_connect_prob.shape) == 2 and \\\n",
    "       block_connect_prob.shape[0] == block_connect_prob.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# block_connect_prob should be a [N, N] tensor\n",
    "N = block_connect_prob.shape[0]\n",
    "block_connect_prob = block_connect_prob.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#参数设置整理\n",
    "block_node_init_kwards = {} if block_node_init_kwards is None else block_node_init_kwards\n",
    "if E_number is not None:\n",
    "    block_node_init_kwards[\"E_number\"] = E_number\n",
    "if I_number is not None:\n",
    "    block_node_init_kwards[\"I_number\"] = I_number\n",
    "\n",
    "if isinstance(block_node_init_kwards, dict):\n",
    "    extern_input_k_sizes = [block_node_init_kwards[\"E_number\"]] * N\n",
    "elif isinstance(block_node_init_kwards, list):\n",
    "    extern_input_k_sizes = [b[\"E_number\"] for b in block_node_init_kwards]\n",
    "else:\n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(perfix):\n",
    "    os.makedirs(perfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = ['single']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = ['single']\n",
    "if not os.path.exists(perfix):\n",
    "    os.makedirs(perfix)\n",
    "with pool(1, initializer=_init, initargs=(block_connect_prob,\n",
    "                                       block_node_init_kwards,\n",
    "                                       extern_input_k_sizes,\n",
    "                                       degree,\n",
    "                                       init_min,\n",
    "                                       init_max,\n",
    "                                       dtype,\n",
    "                                       perfix)) as p:\n",
    "    p.map(_process_dti, range(0, N, 1), chunksize=1)\n",
    "\n",
    "print('total done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "_init(block_connect_prob,\n",
    "block_node_init_kwards,\n",
    "extern_input_k_sizes,\n",
    "degree,\n",
    "init_min,\n",
    "init_max,\n",
    "dtype,\n",
    "perfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype: ['single']\n",
      "d: single\n",
      "processing 0\n",
      "length: 1000 degree: 20\n",
      "generating weight\n",
      "generating idx\n",
      "done 1000\n",
      "done!  0\n"
     ]
    }
   ],
   "source": [
    "_process_dti(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_exist():\n",
    "    for d in dtype:\n",
    "        new_perfix = perfix if len(dtype) == 0 else os.path.join(perfix, d)\n",
    "        os.makedirs(new_perfix, exist_ok=True)\n",
    "        if not os.path.exists(os.path.join(new_perfix, \"block_{}.npz\".format(i))):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dtype:\n",
    "    new_perfix = perfix if len(dtype) == 0 else os.path.join(perfix, d)\n",
    "    os.makedirs(new_perfix, exist_ok=True)\n",
    "    tof =  os.path.exists(os.path.join(new_perfix, \"block_{}.npz\".format(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"processing\", i)\n",
    "prob = block_connect_prob[i, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(block_node_init_kwards, list):#剥皮\n",
    "    block_node_init_kward = block_node_init_kwards[i]\n",
    "else:\n",
    "    block_node_init_kward = block_node_init_kwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(block_node_init_kward, dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 1000 degree: 20\n",
      "generating weight\n",
      "generating idx\n",
      "done 1000\n"
     ]
    }
   ],
   "source": [
    "property = generate_block_node_property(sub_block_idx=i, **block_node_init_kward)\n",
    "output_neuron_idx, input_block_idx, input_neuron_idx, input_channel_offset, weight \\\n",
    "    = connect_for_single_sparse_block(i, block_node_init_kward['E_number'] + block_node_init_kward['I_number'],\n",
    "                                         prob,\n",
    "                                         extern_input_k_sizes=extern_input_k_sizes,\n",
    "                                         degree=degree,\n",
    "                                         init_min=init_min,\n",
    "                                         init_max=init_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 0\n",
      "length: 1000 degree: 20\n",
      "generating weight\n",
      "generating idx\n",
      "done 1000\n",
      "done!  0\n"
     ]
    }
   ],
   "source": [
    "#做了修改，可以跑\n",
    "(\"processing\", i)\n",
    "prob = block_connect_prob[i, :]\n",
    "assert np.abs(1 - prob.sum()) < 1e-4#概率加起来基本上等于1\n",
    "if isinstance(block_node_init_kwards, list):#剥皮\n",
    "    block_node_init_kward = block_node_init_kwards[i]\n",
    "else:\n",
    "    block_node_init_kward = block_node_init_kwards\n",
    "assert isinstance(block_node_init_kward, dict)\n",
    "property = generate_block_node_property(sub_block_idx=i, **block_node_init_kward)\n",
    "output_neuron_idx, input_block_idx, input_neuron_idx, input_channel_offset, weight \\\n",
    "    = connect_for_single_sparse_block(i, block_node_init_kward['E_number'] + block_node_init_kward['I_number'],\n",
    "                                         prob,\n",
    "                                         extern_input_k_sizes=extern_input_k_sizes,\n",
    "                                         degree=degree,\n",
    "                                         init_min=init_min,\n",
    "                                         init_max=init_max)\n",
    "\n",
    "if isinstance(dtype, str):#要小心dtype的形式\n",
    "    dtype = [dtype]\n",
    "\n",
    "for d in dtype:#目录创建\n",
    "    new_perfix = perfix if len(dtype) == 0 else os.path.join(perfix, d)\n",
    "    os.makedirs(new_perfix, exist_ok=True)\n",
    "\n",
    "    if d == \"single\":\n",
    "        _weight = weight#没有half意味着dtype=float32\n",
    "    elif d == 'half':\n",
    "        _weight = weight.astype(np.float16)#half意味着数据类型为float16\n",
    "    else:\n",
    "        raise ValueError\n",
    "    np.savez(os.path.join(new_perfix, \"block_{}\".format(i)),#储存各参数\n",
    "             property=np.ascontiguousarray(property),\n",
    "             output_neuron_idx=np.ascontiguousarray(output_neuron_idx),\n",
    "             input_block_idx=np.ascontiguousarray(input_block_idx),\n",
    "             input_neuron_idx=np.ascontiguousarray(input_neuron_idx),\n",
    "             input_channel_offset=np.ascontiguousarray(input_channel_offset),\n",
    "             weight=np.ascontiguousarray(_weight))\n",
    "\n",
    "print(\"done! \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#做了修改\n",
    "def connect_for_single_sparse_block(block_idx, k, extern_input_rate, extern_input_k_sizes, degree = int(1e3),\n",
    "                                    init_min = 0,\n",
    "                                    init_max = 1,\n",
    "                                    s = 0,\n",
    "                                    e = -1):\n",
    "    # extern_input_rate only works for E neurons.\n",
    "\n",
    "    # this function is pertty slow.\n",
    "\n",
    "    # we assume that the permution\n",
    "\n",
    "    if e == -1:\n",
    "        e = k\n",
    "    assert 0 <= s < e <= k\n",
    "\n",
    "    print(\"length:\", e - s, \"degree:\", degree)\n",
    "    print(\"generating weight\")\n",
    "    connect_weight = np.random.rand(e - s, degree, 2).astype(np.float32) * (init_max - init_min) + init_min\n",
    "    print(\"generating idx\")\n",
    "\n",
    "    E_neuron_thresh = extern_input_k_sizes[block_idx]\n",
    "\n",
    "    # connect_weight[is_E_neuron == 0] *= 4\n",
    "\n",
    "    output_neuron_idx = np.broadcast_to(np.arange(s, e, dtype=np.uint32)[:, None], (e-s, degree))\n",
    "\n",
    "    _extern_input_k_sizes = np.array(extern_input_k_sizes, dtype=np.int64)\n",
    "    extern_input_rate = np.add.accumulate(extern_input_rate)[:-1]\n",
    "\n",
    "    @jit(nogil=True, nopython=True)\n",
    "    def _run(i):\n",
    "        input_block_idx = np.zeros(degree, dtype=np.int16)#初始化\n",
    "        input_channel_offset = np.zeros(degree, dtype=np.uint8)#初始化\n",
    "        while True:\n",
    "            k_idx = get_k_idx(k, degree, i)#不能与自己连接，所以排除i\n",
    "            k_idx_is_E = (k_idx < E_neuron_thresh)##与E_neuron产生随机的连接关系？\n",
    "            k_idx_is_I = (k_idx >= E_neuron_thresh)##与I_neuron产生随机的连接关系？\n",
    "            if k_idx_is_I.shape[0] > 0:\n",
    "                break\n",
    "        # connect_weight[i, k_idx_is_I] *= connect_weight[i, k_idx_is_E].sum() / connect_weight[i, k_idx_is_I].sum()\n",
    "\n",
    "        input_block_idx[k_idx_is_I] = block_idx#设置I_neuron\n",
    "\n",
    "        r = np.random.rand(np.count_nonzero(k_idx_is_E))\n",
    "        E_in_comming = np.searchsorted(extern_input_rate, r, 'right').astype(np.int16)\n",
    "\n",
    "        input_block_idx[k_idx_is_E] = E_in_comming#设置E_neuron\n",
    "\n",
    "        input_neuron_idx = k_idx.astype(np.uint32)\n",
    "        for _idx, max_idx in enumerate(_extern_input_k_sizes):\n",
    "            if _idx != block_idx:\n",
    "                extern_incomming_idx = (input_block_idx == _idx).nonzero()[0]\n",
    "                extern_outcomming_idx = get_k_idx(max_idx, extern_incomming_idx.shape[0], -1)\n",
    "                input_neuron_idx[extern_incomming_idx] = extern_outcomming_idx\n",
    "\n",
    "        input_channel_offset[k_idx_is_E] = 0 #设置offset\n",
    "        input_channel_offset[k_idx_is_I] = 2 #设置offset\n",
    "\n",
    "        input_block_idx -= block_idx\n",
    "        return input_block_idx, input_neuron_idx, input_channel_offset\n",
    "\n",
    "    input_block_idx, input_neuron_idx, input_channel_offset = list(zip(list(map(_run, range(s, e)))[0]))#核心计算过程\n",
    "    output_neuron_idx = output_neuron_idx.reshape([-1])\n",
    "    connect_weight = connect_weight.reshape([-1, 2])\n",
    "\n",
    "    print(\"done\", e - s)\n",
    "    return output_neuron_idx, input_block_idx, input_neuron_idx, input_channel_offset, connect_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "result00=list(map(_run, range(0, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        dtype=int16),),\n",
       " (array([851, 499, 682, 395, 602, 349, 858, 178, 128, 591, 297, 640, 883,\n",
       "         990, 667,  54, 470, 942, 892,  45], dtype=uint32),),\n",
       " (array([2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 2, 0],\n",
       "        dtype=uint8),)]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(result00[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 1000)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(s, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_idx, k, extern_input_rate, extern_input_k_sizes, degree = int(1e3),\n",
    "                                    init_min = 0,\n",
    "                                    init_max = 1,\n",
    "                                    s = 0,\n",
    "                                    e = -1\n",
    "\n",
    "connect_for_single_sparse_block(i, block_node_init_kward['E_number'] + block_node_init_kward['I_number'],\n",
    "                                         prob,\n",
    "                                         extern_input_k_sizes=extern_input_k_sizes,\n",
    "                                         degree=degree,\n",
    "                                         init_min=init_min,\n",
    "                                         init_max=init_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_idx =i\n",
    "k=block_node_init_kward['E_number'] + block_node_init_kward['I_number']  \n",
    "extern_input_rate = prob\n",
    "extern_input_k_sizes=extern_input_k_sizes\n",
    "degree=degree\n",
    "init_min=init_min\n",
    "init_max=init_max\n",
    "s = 0\n",
    "e = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 1000 degree: 20\n",
      "generating weight\n",
      "generating idx\n"
     ]
    }
   ],
   "source": [
    "if e == -1:\n",
    "    e = k\n",
    "assert 0 <= s < e <= k\n",
    "\n",
    "print(\"length:\", e - s, \"degree:\", degree)\n",
    "print(\"generating weight\")\n",
    "connect_weight = np.random.rand(e - s, degree, 2).astype(np.float32) * (init_max - init_min) + init_min\n",
    "print(\"generating idx\")\n",
    "\n",
    "E_neuron_thresh = extern_input_k_sizes[block_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect_weight[is_E_neuron == 0] *= 4\n",
    "\n",
    "output_neuron_idx = np.broadcast_to(np.arange(s, e, dtype=np.uint32)[:, None], (e-s, degree))\n",
    "\n",
    "_extern_input_k_sizes = np.array(extern_input_k_sizes, dtype=np.int64)\n",
    "extern_input_rate = np.add.accumulate(extern_input_rate)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nogil=True, nopython=True)\n",
    "def _run(i):\n",
    "    input_block_idx = np.zeros(degree, dtype=np.int16)#初始化\n",
    "    input_channel_offset = np.zeros(degree, dtype=np.uint8)#初始化\n",
    "    while True:\n",
    "        k_idx = get_k_idx(k, degree, i)#不能与自己连接，所以排除i\n",
    "        k_idx_is_E = (k_idx < E_neuron_thresh)##与E_neuron产生随机的连接关系？\n",
    "        k_idx_is_I = (k_idx >= E_neuron_thresh)##与I_neuron产生随机的连接关系？\n",
    "        if k_idx_is_I.shape[0] > 0:\n",
    "            break\n",
    "    # connect_weight[i, k_idx_is_I] *= connect_weight[i, k_idx_is_E].sum() / connect_weight[i, k_idx_is_I].sum()\n",
    "\n",
    "    input_block_idx[k_idx_is_I] = block_idx#设置I_neuron\n",
    "\n",
    "    r = np.random.rand(np.count_nonzero(k_idx_is_E))\n",
    "    E_in_comming = np.searchsorted(extern_input_rate, r, 'right').astype(np.int16)\n",
    "\n",
    "    input_block_idx[k_idx_is_E] = E_in_comming#设置E_neuron\n",
    "\n",
    "    input_neuron_idx = k_idx.astype(np.uint32)\n",
    "    for _idx, max_idx in enumerate(_extern_input_k_sizes):\n",
    "        if _idx != block_idx:\n",
    "            extern_incomming_idx = (input_block_idx == _idx).nonzero()[0]\n",
    "            extern_outcomming_idx = get_k_idx(max_idx, extern_incomming_idx.shape[0], -1)\n",
    "            input_neuron_idx[extern_incomming_idx] = extern_outcomming_idx\n",
    "\n",
    "    input_channel_offset[k_idx_is_E] = 0 #设置offset\n",
    "    input_channel_offset[k_idx_is_I] = 2 #设置offset\n",
    "\n",
    "    input_block_idx -= block_idx\n",
    "    return input_block_idx, input_neuron_idx, input_channel_offset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.add.accumulate(extern_input_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1]], dtype=uint32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0, 2, dtype=np.uint32)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_block_idx = np.zeros(degree, dtype=np.int16)#初始化\n",
    "input_channel_offset = np.zeros(degree, dtype=np.uint8)#初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    k_idx = get_k_idx(k, degree, i)#不能与自己连接，所以排除i\n",
    "    k_idx_is_E = (k_idx < E_neuron_thresh)##与E_neuron产生随机的连接关系？\n",
    "    k_idx_is_I = (k_idx >= E_neuron_thresh)##与I_neuron产生随机的连接关系？\n",
    "    if k_idx_is_I.shape[0] > 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_block_idx[k_idx_is_I] = block_idx#设置I_neuron\n",
    "\n",
    "r = np.random.rand(np.count_nonzero(k_idx_is_E))\n",
    "E_in_comming = np.searchsorted(extern_input_rate, r, 'right').astype(np.int16)\n",
    "\n",
    "input_block_idx[k_idx_is_E] = E_in_comming#设置E_neuron\n",
    "\n",
    "input_neuron_idx = k_idx.astype(np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([921, 199, 628, 704, 952, 734, 590, 705, 493, 411, 329, 944, 922,\n",
       "        90,  21, 538, 458, 282, 460, 569], dtype=int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _idx, max_idx in enumerate(_extern_input_k_sizes):\n",
    "    if _idx != block_idx:\n",
    "        extern_incomming_idx = (input_block_idx == _idx).nonzero()[0]\n",
    "        extern_outcomming_idx = get_k_idx(max_idx, extern_incomming_idx.shape[0], -1)\n",
    "        input_neuron_idx[extern_incomming_idx] = extern_outcomming_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_channel_offset[k_idx_is_E] = 0 #设置offset\n",
    "input_channel_offset[k_idx_is_I] = 2 #设置offset\n",
    "\n",
    "input_block_idx -= block_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nogil=True, nopython=True)\n",
    "def get_k_idx(max_k, num, except_idx):\n",
    "    if except_idx < 0:\n",
    "        assert num <= max_k\n",
    "        if num == max_k:\n",
    "            return np.arange(0, max_k)\n",
    "    elif except_idx is not None:\n",
    "        assert num < max_k\n",
    "        if num == max_k - 1:\n",
    "            return np.concatenate((np.arange(0, except_idx), np.arange(except_idx+1, num)))#输出除了except_idx之外的其他连续数列，从0到num\n",
    "\n",
    "    while True:\n",
    "        k_idx = np.unique(np.random.randint(0, max_k, num*2))#随机生成一个2*num规模的随机整数列，去掉重复值，取值为0-max_k\n",
    "        k_idx = k_idx[np.random.permutation(k_idx.shape[0])]#对上述产生的序列进行随机打乱\n",
    "        if except_idx is not None:\n",
    "            k_idx = k_idx[k_idx != except_idx] #删掉except_idx\n",
    "        k_idx = k_idx[:num]#截取num个元素\n",
    "        if k_idx.shape[0] == num:\n",
    "            break\n",
    "    return k_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_idx = get_k_idx(k, degree, i)#不能与自己连接，所以排除i\n",
    "k_idx_is_I.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_block_idx = np.zeros(degree, dtype=np.int16)#初始化\n",
    "input_channel_offset = np.zeros(degree, dtype=np.uint8)#初始化\n",
    "while True:\n",
    "    k_idx = get_k_idx(k, degree, i)#不能与自己连接，所以排除i\n",
    "    k_idx_is_E = (k_idx < E_neuron_thresh)##与E_neuron产生随机的连接关系？\n",
    "    k_idx_is_I = (k_idx >= E_neuron_thresh)##与I_neuron产生随机的连接关系？\n",
    "    if k_idx_is_I.shape[0] > 0:\n",
    "        break\n",
    "# connect_weight[i, k_idx_is_I] *= connect_weight[i, k_idx_is_E].sum() / connect_weight[i, k_idx_is_I].sum()\n",
    "\n",
    "input_block_idx[k_idx_is_I] = block_idx#设置I_neuron\n",
    "\n",
    "r = np.random.rand(np.count_nonzero(k_idx_is_E))\n",
    "E_in_comming = np.searchsorted(extern_input_rate, r, 'right').astype(np.int16)\n",
    "\n",
    "input_block_idx[k_idx_is_E] = E_in_comming#设置E_neuron\n",
    "\n",
    "input_neuron_idx = k_idx.astype(np.uint32)\n",
    "input_channel_offset[k_idx_is_E] = 0 #设置offset\n",
    "input_channel_offset[k_idx_is_I] = 2 #设置offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
